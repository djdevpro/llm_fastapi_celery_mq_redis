# ğŸš€ LLM Stream API

> **API LLM scalable** avec Celery + Redis.

[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.124-green.svg)](https://fastapi.tiangolo.com)
[![Celery](https://img.shields.io/badge/Celery-5.4-green.svg)](https://docs.celeryq.dev)
[![Docker](https://img.shields.io/badge/Docker-ready-blue.svg)](https://docker.com)

---

## ğŸ“ Structure du projet

```
llm_fastapi_mq/
â”œâ”€â”€ app/                        # Code source
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ main.py             # FastAPI application
â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ llm_tasks.py        # TÃ¢ches Celery
â”‚   â”œâ”€â”€ services/               # Services legacy (RabbitMQ)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py               # Configuration
â”‚   â””â”€â”€ celery_app.py           # Configuration Celery
â”‚
â”œâ”€â”€ docker/                     # Fichiers Docker
â”‚   â”œâ”€â”€ Dockerfile.api          # Image API
â”‚   â”œâ”€â”€ Dockerfile.worker       # Image Worker Celery
â”‚   â”œâ”€â”€ entrypoint-api.sh       # Entrypoint API
â”‚   â”œâ”€â”€ entrypoint-worker.sh    # Entrypoint Worker
â”‚   â””â”€â”€ docker-compose.yml      # Orchestration
â”‚
â”œâ”€â”€ tests/                      # Tests
â”‚   â”œâ”€â”€ test_celery.py
â”‚   â””â”€â”€ test_concurrent.py
â”‚
â”œâ”€â”€ chat.html                   # Interface web
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ DÃ©marrage rapide

### 1. Configuration

```bash
cp .env.example .env
# Ã‰diter avec vos clÃ©s
```

### 2. Docker Compose

```bash
cd docker

# Lancer API + Worker + Redis
docker-compose up -d

# Avec monitoring Flower
docker-compose --profile monitoring up -d

# Scaler les workers
docker-compose up -d --scale worker=5
```

### 3. VÃ©rification

```bash
curl http://localhost:8007/health/full
# {"status":"ok","redis":"connected","celery_workers":"active","openai":"configured"}
```

---

## ğŸ“¡ API Endpoints

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| `GET` | `/health` | Health check |
| `GET` | `/health/full` | Statut complet |
| `POST` | `/chat` | Chat sync (streaming direct) |
| `POST` | `/chat/async` | **Chat async (Celery)** âš¡ |
| `GET` | `/chat/{task_id}` | Status tÃ¢che |
| `GET` | `/stream/{session_id}` | SSE streaming |
| `POST` | `/embeddings` | Batch embeddings |
| `GET` | `/stats` | Stats queues |

### Exemple

```bash
# 1. Envoie requÃªte async
curl -X POST http://localhost:8007/chat/async \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello!", "priority": 5}'

# RÃ©ponse:
# {"status":"queued","task_id":"xxx","session_id":"yyy","stream_url":"/stream/yyy"}

# 2. Ã‰coute le stream
curl -N http://localhost:8007/stream/yyy
```

---

## âš™ï¸ Variables d'environnement

```env
# OpenAI
OPENAI_API_KEY=sk-xxx

# Redis
REDIS_URL=redis://redis:6379/0

# API
PORT=8007
UVICORN_WORKERS=4

# Celery
CELERY_CONCURRENCY=4
CELERY_QUEUES=high,default,low
CELERY_LOGLEVEL=info

# Rate Limiting
LLM_RPM=500
LLM_TPM=100000
```

---

## ğŸ³ Docker

### Images

| Image | Description | Entrypoint |
|-------|-------------|------------|
| `Dockerfile.api` | FastAPI API | `entrypoint-api.sh` |
| `Dockerfile.worker` | Celery Worker | `entrypoint-worker.sh` |

### Services

| Service | Description | Scale |
|---------|-------------|-------|
| `api` | API FastAPI | 1 |
| `worker` | Celery workers | âˆ |
| `worker-high` | Workers prioritÃ© haute | âˆ |
| `redis` | Broker + cache | 1 |
| `flower` | Monitoring | 1 |

### Commandes

```bash
cd docker

# DÃ©marrer
docker-compose up -d

# Logs
docker-compose logs -f api worker

# Scaler
docker-compose up -d --scale worker=10

# Monitoring (http://localhost:5555)
docker-compose --profile monitoring up -d

# Stop
docker-compose down
```

---

## ğŸ§ª Tests

```bash
# Tests Celery
pytest tests/test_celery.py -v -s

# Tous les tests
pytest tests/ -v -s
```

---

## ğŸ–¥ï¸ Interface Web

```bash
open chat.html
```

3 modes : **Celery**, **RabbitMQ**, **Direct**

---

## ğŸ“„ License

MIT
